{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7424766,"sourceType":"datasetVersion","datasetId":4320051}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport time\nfrom pathlib import Path\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport timm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T10:12:45.171606Z","iopub.execute_input":"2025-03-26T10:12:45.171892Z","iopub.status.idle":"2025-03-26T10:12:45.338986Z","shell.execute_reply.started":"2025-03-26T10:12:45.171871Z","shell.execute_reply":"2025-03-26T10:12:45.338291Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Configuration\nDATASET_DIR = \"/kaggle/input/sugarcane-leaf-disease-dataset\"\nCLASS_NAMES = [\"Healthy\", \"Mosaic\", \"RedRot\", \"Rust\", \"Yellow\"]\nNUM_CLASSES = len(CLASS_NAMES)\nINPUT_SIZE = 224\nBATCH_SIZE = 32\nNUM_WORKERS = 4\nEPOCHS = 30\nLEARNING_RATE = 1e-4\nWEIGHT_DECAY = 1e-5\nMODEL_NAME = \"timm/convnextv2_tiny.fcmae\"\nSEED = 1729","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T10:12:47.619759Z","iopub.execute_input":"2025-03-26T10:12:47.620093Z","iopub.status.idle":"2025-03-26T10:12:47.624643Z","shell.execute_reply.started":"2025-03-26T10:12:47.620066Z","shell.execute_reply":"2025-03-26T10:12:47.623812Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T10:12:57.991737Z","iopub.execute_input":"2025-03-26T10:12:57.992011Z","iopub.status.idle":"2025-03-26T10:12:58.091563Z","shell.execute_reply.started":"2025-03-26T10:12:57.991992Z","shell.execute_reply":"2025-03-26T10:12:58.09071Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define transforms\ntrain_transform = transforms.Compose([\n    transforms.Resize((INPUT_SIZE, INPUT_SIZE)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((INPUT_SIZE, INPUT_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T10:13:22.939923Z","iopub.execute_input":"2025-03-26T10:13:22.940258Z","iopub.status.idle":"2025-03-26T10:13:22.945898Z","shell.execute_reply.started":"2025-03-26T10:13:22.940232Z","shell.execute_reply":"2025-03-26T10:13:22.944959Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load dataset\nimage_paths = []\nlabels = []\n\nfor i, class_name in enumerate(CLASS_NAMES):\n    class_dir = Path(DATASET_DIR) / class_name\n    class_images = list(class_dir.glob(\"*.jpg\")) + list(class_dir.glob(\"*.jpeg\")) + list(class_dir.glob(\"*.png\"))\n    \n    image_paths.extend([str(img_path) for img_path in class_images])\n    labels.extend([i] * len(class_images))\n\nprint(f\"Total images found: {len(image_paths)}\")\n\n# Split dataset\ntrain_idx, temp_idx = train_test_split(\n    list(range(len(image_paths))), \n    test_size=0.3,\n    stratify=labels,\n    random_state=SEED\n)\n\nval_idx, test_idx = train_test_split(\n    temp_idx,\n    test_size=0.5,\n    stratify=[labels[i] for i in temp_idx],\n    random_state=SEED\n)\n\n# Create data loaders\ntrain_loader = DataLoader(\n    [(Image.open(image_paths[i]).convert('RGB'), labels[i]) for i in train_idx],\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    num_workers=NUM_WORKERS,\n    pin_memory=True,\n    collate_fn=lambda x: (\n        torch.stack([train_transform(img) for img, _ in x]),\n        torch.tensor([label for _, label in x])\n    )\n)\n\nval_loader = DataLoader(\n    [(Image.open(image_paths[i]).convert('RGB'), labels[i]) for i in val_idx],\n    batch_size=BATCH_SIZE,\n    shuffle=False,\n    num_workers=NUM_WORKERS,\n    pin_memory=True,\n    collate_fn=lambda x: (\n        torch.stack([val_transform(img) for img, _ in x]),\n        torch.tensor([label for _, label in x])\n    )\n)\n\ntest_loader = DataLoader(\n    [(Image.open(image_paths[i]).convert('RGB'), labels[i]) for i in test_idx],\n    batch_size=BATCH_SIZE,\n    shuffle=False,\n    num_workers=NUM_WORKERS,\n    pin_memory=True,\n    collate_fn=lambda x: (\n        torch.stack([val_transform(img) for img, _ in x]),\n        torch.tensor([label for _, label in x])\n    )\n)\n\nprint(f\"Train set size: {len(train_loader.dataset)}\")\nprint(f\"Validation set size: {len(val_loader.dataset)}\")\nprint(f\"Test set size: {len(test_loader.dataset)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T10:14:32.31571Z","iopub.execute_input":"2025-03-26T10:14:32.315992Z","iopub.status.idle":"2025-03-26T10:15:19.740659Z","shell.execute_reply.started":"2025-03-26T10:14:32.31597Z","shell.execute_reply":"2025-03-26T10:15:19.739913Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create model\nmodel = timm.create_model(\n    MODEL_NAME,\n    pretrained=True,\n    num_classes=NUM_CLASSES\n)\n\n# Replace classifier with dropout\noriginal_fc = model.head.fc\nmodel.head.fc = nn.Sequential(\n    nn.Dropout(0.2),\n    nn.Linear(original_fc.in_features, NUM_CLASSES)\n)\n\n# Move model to device\nmodel = model.to(device)\n\n# Loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n\n# Training history\nhistory = {\n    'train_loss': [],\n    'train_acc': [],\n    'val_loss': [],\n    'val_acc': []\n}\n\n# Early stopping\nbest_val_loss = float('inf')\npatience = 7\npatience_counter = 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T10:15:53.811819Z","iopub.execute_input":"2025-03-26T10:15:53.812125Z","iopub.status.idle":"2025-03-26T10:15:55.372435Z","shell.execute_reply.started":"2025-03-26T10:15:53.812088Z","shell.execute_reply":"2025-03-26T10:15:55.371419Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_one_epoch(model, dataloader, criterion, optimizer, device):\n    model.train()\n    total_loss = 0\n    correct = 0\n    total = 0\n    \n    for inputs, labels in tqdm(dataloader, desc='Training'):\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += labels.size(0)\n        correct += predicted.eq(labels).sum().item()\n    \n    return total_loss / len(dataloader), correct / total\n\ndef validate(model, dataloader, criterion, device):\n    model.eval()\n    total_loss = 0\n    correct = 0\n    total = 0\n    \n    with torch.no_grad():\n        for inputs, labels in tqdm(dataloader, desc='Validation'):\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            \n            total_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n    \n    return total_loss / len(dataloader), correct / total","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T10:16:11.354161Z","iopub.execute_input":"2025-03-26T10:16:11.354503Z","iopub.status.idle":"2025-03-26T10:16:11.361683Z","shell.execute_reply.started":"2025-03-26T10:16:11.354476Z","shell.execute_reply":"2025-03-26T10:16:11.360732Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Training loop\nfor epoch in range(EPOCHS):\n    print(f'\\nEpoch {epoch+1}/{EPOCHS}')\n    \n    # Train\n    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n    \n    # Validate\n    val_loss, val_acc = validate(model, val_loader, criterion, device)\n    \n    # Update learning rate\n    scheduler.step(val_loss)\n    \n    # Update history\n    history['train_loss'].append(train_loss)\n    history['train_acc'].append(train_acc)\n    history['val_loss'].append(val_loss)\n    history['val_acc'].append(val_acc)\n    \n    print(f'Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}')\n    print(f'Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}')\n    \n    # Early stopping\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        patience_counter = 0\n        # Save best model\n        torch.save(model.state_dict(), 'best_model.pt')\n    else:\n        patience_counter += 1\n        if patience_counter >= patience:\n            print('Early stopping triggered')\n            break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T10:16:20.71255Z","iopub.execute_input":"2025-03-26T10:16:20.712843Z","iopub.status.idle":"2025-03-26T10:35:11.238641Z","shell.execute_reply.started":"2025-03-26T10:16:20.712822Z","shell.execute_reply":"2025-03-26T10:35:11.237615Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load best model\nmodel.load_state_dict(torch.load('best_model.pt'))\n\n# Test function\ndef test(model, dataloader, criterion, device):\n    model.eval()\n    total_loss = 0\n    all_preds = []\n    all_labels = []\n    \n    with torch.no_grad():\n        for inputs, labels in tqdm(dataloader, desc='Testing'):\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            \n            total_loss += loss.item()\n            _, preds = outputs.max(1)\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n    \n    return total_loss / len(dataloader), all_preds, all_labels\n\n# Run test\ntest_loss, test_preds, test_labels = test(model, test_loader, criterion, device)\n\n# Print classification report\nprint('\\nClassification Report:')\nprint(classification_report(test_labels, test_preds, target_names=CLASS_NAMES))\n\n# Plot confusion matrix\nplt.figure(figsize=(10, 8))\ncm = confusion_matrix(test_labels, test_preds)\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n            xticklabels=CLASS_NAMES,\n            yticklabels=CLASS_NAMES)\nplt.title('Confusion Matrix')\nplt.ylabel('True Label')\nplt.xlabel('Predicted Label')\nplt.show()\n\n# Plot training history\nplt.figure(figsize=(12, 4))\n\nplt.subplot(1, 2, 1)\nplt.plot(history['train_loss'], label='Train Loss')\nplt.plot(history['val_loss'], label='Val Loss')\nplt.title('Loss')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(history['train_acc'], label='Train Acc')\nplt.plot(history['val_acc'], label='Val Acc')\nplt.title('Accuracy')\nplt.legend()\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T10:38:24.234604Z","iopub.execute_input":"2025-03-26T10:38:24.234945Z","iopub.status.idle":"2025-03-26T10:38:28.082623Z","shell.execute_reply.started":"2025-03-26T10:38:24.234921Z","shell.execute_reply":"2025-03-26T10:38:28.081645Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}